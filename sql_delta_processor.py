import json
import time
from datetime import datetime, timezone
from typing import Dict, Any, List
import pyodbc
import pandas as pd
import daft
from daft.io import IOConfig, AzureConfig
from azure.storage.blob import BlobServiceClient

STORAGE_CONNECTION = "DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=windfarm6storage;AccountKey=X7YVa9h/iiKRdw0sYlgaUkb8RFi3U+FRnKR/86DkYxiT8WB4KVPOeBxvGdp0yHDYRMAVVa1FpyIF+AStPVbVPQ==;BlobEndpoint=https://windfarm6storage.blob.core.windows.net/"

SQL_CONNECTION = "DRIVER={ODBC Driver 18 for SQL Server};SERVER=windfarm6-sql-northeu.database.windows.net;DATABASE=WindFarmDB;UID=sqladmin;PWD=WindFarm123!;Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;"

STORAGE_ACCOUNT_NAME = "windfarm6storage"
STORAGE_ACCOUNT_KEY = "X7YVa9h/iiKRdw0sYlgaUkb8RFi3U+FRnKR/86DkYxiT8WB4KVPOeBxvGdp0yHDYRMAVVa1FpyIF+AStPVbVPQ=="
CONTAINER_NAME = "telemetry-data"
NEW_DELTA_TABLE_PATH = "delta-lake-turbine-telemetry-full"

class NewTableProcessor:
    """–ü—Ä–æ—Ü–µ—Å–æ—Ä –∑ Delta Lake —Ç–∞–±–ª–∏—Ü–µ—é"""
    
    def __init__(self):
        print(f" –ù–æ–≤–∞ —Ç–∞–±–ª–∏—Ü—è: {NEW_DELTA_TABLE_PATH}")
        
        self.blob_service = BlobServiceClient.from_connection_string(STORAGE_CONNECTION)
        self.ensure_container_exists()
        
        self.io_config = IOConfig(
            azure=AzureConfig(
                storage_account=STORAGE_ACCOUNT_NAME,
                access_key=STORAGE_ACCOUNT_KEY
            )
        )
        
        print(" New Table Processor —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ")
    
    def ensure_container_exists(self):
        try:
            self.blob_service.create_container(CONTAINER_NAME)
            print(f" –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä {CONTAINER_NAME} —Å—Ç–≤–æ—Ä–µ–Ω–æ")
        except Exception:
            print(f" –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä {CONTAINER_NAME} –≤–∂–µ —ñ—Å–Ω—É—î")
    
    def get_sql_connection(self):
        try:
            return pyodbc.connect(SQL_CONNECTION)
        except Exception as e:
            print(f" SQL –ø–æ–º–∏–ª–∫–∞: {e}")
            return None
    
    def clean_text_field(self, text_value) -> str:
        if pd.isna(text_value) or text_value is None:
            return ''
        text_str = str(text_value)
        if '?' in text_str and len([c for c in text_str if c == '?']) > 3:
            return 'Maintenance completed successfully'
        return text_str
    
    def get_all_turbine_ids(self) -> List[str]:
        conn = self.get_sql_connection()
        if not conn:
            return []
        
        try:
            query = "SELECT DISTINCT turbine_id FROM dbo.Turbines ORDER BY turbine_id"
            df = pd.read_sql(query, conn)
            turbine_ids = df['turbine_id'].tolist()
            print(f" –ó–Ω–∞–π–¥–µ–Ω–æ {len(turbine_ids)} —Ç—É—Ä–±—ñ–Ω: {', '.join(turbine_ids)}")
            return turbine_ids
        except Exception as e:
            print(f" –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Å–ø–∏—Å–∫—É —Ç—É—Ä–±—ñ–Ω: {e}")
            return []
        finally:
            conn.close()
    
    def get_enriched_data_for_turbine(self, turbine_id: str, limit: int = 1) -> List[Dict[str, Any]]:
        conn = self.get_sql_connection()
        if not conn:
            return []
        
        try:
            query = f"""
            SELECT TOP ({limit})
                turbine_id, timestamp, output_power, rotor_rpm, max_power_limit,
                voltage, current_amperage, power_factor, data_quality_score, sensor_status,
                location_name, latitude, longitude, manufacturer, model, nominal_power_kw, 
                turbine_status, installation_date,
                wind_speed_ms, wind_direction_degrees, temperature_celsius,
                humidity_percent, air_pressure_hpa, visibility_km, precipitation_mm,
                maintenance_status, last_maintenance_date, next_maintenance_date,
                efficiency_rating, operating_hours, maintenance_notes, technician_name,
                efficiency_percent, operational_status, calculated_power_kw, load_factor,
                partition_year, partition_month, partition_day,
                enrichment_version, enrichment_source, processed_by
            FROM dbo.EnrichedTelemetryView 
            WHERE turbine_id = ?
            ORDER BY timestamp DESC
            """
            
            df = pd.read_sql(query, conn, params=[turbine_id])
            
            if len(df) == 0:
                print(f" –ù–µ–º–∞—î –∑–±–∞–≥–∞—á–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è {turbine_id}")
                return []
            
            print(f" –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è {turbine_id}")
            
            sensor_metadata = self._get_sensor_metadata_for_turbine(turbine_id)
            
            enriched_list = []
            for _, row in df.iterrows():
                record = {
                    "turbine_id": turbine_id,
                    "timestamp": row['timestamp'].isoformat() if pd.notna(row['timestamp']) else datetime.now(timezone.utc).isoformat(),
                    "output_power": float(row['output_power']) if pd.notna(row['output_power']) else 0.0,
                    "rotor_rpm": float(row['rotor_rpm']) if pd.notna(row['rotor_rpm']) else 0.0,
                    "max_power_limit": float(row['max_power_limit']) if pd.notna(row['max_power_limit']) else 0.0,
                    "voltage": float(row['voltage']) if pd.notna(row['voltage']) else 0.0,
                    "current": float(row['current_amperage']) if pd.notna(row['current_amperage']) else 0.0,
                    "power_factor": float(row['power_factor']) if pd.notna(row['power_factor']) else 0.0,
                    
                    "turbine_metadata": {
                        "turbine_name": str(row['location_name']) if pd.notna(row['location_name']) else '',
                        "location_lat": float(row['latitude']) if pd.notna(row['latitude']) else 0.0,
                        "location_lng": float(row['longitude']) if pd.notna(row['longitude']) else 0.0,
                        "manufacturer": str(row['manufacturer']) if pd.notna(row['manufacturer']) else '',
                        "model": str(row['model']) if pd.notna(row['model']) else '',
                        "nominal_power_kw": int(row['nominal_power_kw']) if pd.notna(row['nominal_power_kw']) else 0,
                        "installation_date": row['installation_date'].isoformat() if pd.notna(row['installation_date']) else '',
                        "status": str(row['turbine_status']) if pd.notna(row['turbine_status']) else 'unknown'
                    },
                    
                    "sensor_metadata": sensor_metadata,
                    
                    "calculated_metrics": {
                        "efficiency_percent": float(row['efficiency_percent']) if pd.notna(row['efficiency_percent']) else 0.0,
                        "operational_status": str(row['operational_status']) if pd.notna(row['operational_status']) else '',
                        "calculated_power_kw": float(row['calculated_power_kw']) if pd.notna(row['calculated_power_kw']) else 0.0
                    },
                    
                    "enrichment_info": {
                        "processing_timestamp": datetime.now(timezone.utc).isoformat(),
                        "data_quality_score": float(row['data_quality_score']) if pd.notna(row['data_quality_score']) else 1.0,
                        "enrichment_version": "8.0_NewTable_Full",
                        "source": "Azure SQL Database + New Delta Table",
                        "processed_by": "New Table Processor"
                    },
                    
                    "environmental_data": {
                        "wind_speed_ms": float(row['wind_speed_ms']) if pd.notna(row['wind_speed_ms']) else 0.0,
                        "wind_direction_degrees": int(row['wind_direction_degrees']) if pd.notna(row['wind_direction_degrees']) else 0,
                        "temperature_celsius": float(row['temperature_celsius']) if pd.notna(row['temperature_celsius']) else 0.0,
                        "humidity_percent": float(row['humidity_percent']) if pd.notna(row['humidity_percent']) else 0.0,
                        "air_pressure_hpa": float(row['air_pressure_hpa']) if pd.notna(row['air_pressure_hpa']) else 0.0,
                        "visibility_km": float(row['visibility_km']) if pd.notna(row['visibility_km']) else 0.0,
                        "precipitation_mm": float(row['precipitation_mm']) if pd.notna(row['precipitation_mm']) else 0.0
                    },
                    
                    "maintenance_data": {
                        "maintenance_status": str(row['maintenance_status']) if pd.notna(row['maintenance_status']) else '',
                        "last_maintenance_date": row['last_maintenance_date'].isoformat() if pd.notna(row['last_maintenance_date']) else '',
                        "next_maintenance_date": row['next_maintenance_date'].isoformat() if pd.notna(row['next_maintenance_date']) else '',
                        "efficiency_rating": float(row['efficiency_rating']) if pd.notna(row['efficiency_rating']) else 0.0,
                        "operating_hours": float(row['operating_hours']) if pd.notna(row['operating_hours']) else 0.0,
                        "maintenance_notes": self.clean_text_field(row['maintenance_notes']) if pd.notna(row['maintenance_notes']) else "Regular maintenance completed successfully",
                        "technician_name": self.clean_text_field(row['technician_name']) if pd.notna(row['technician_name']) else f"Technician_{turbine_id[-1]}"
                    }
                }
                
                enriched_list.append(record)
            
            return enriched_list
            
        except Exception as e:
            print(f" –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–ª—è {turbine_id}: {e}")
            return []
        finally:
            conn.close()
    
    def _get_sensor_metadata_for_turbine(self, turbine_id: str) -> Dict[str, Dict]:
        conn = self.get_sql_connection()
        if not conn:
            return {}
        
        try:
            query = """
            SELECT 
                st.parameter_name,
                st.sensor_name,
                st.unit_of_measurement,
                st.description,
                ts.sensor_type_id,
                ts.turbine_sensor_id
            FROM dbo.TurbineSensors ts
            INNER JOIN dbo.SensorTypes st ON ts.sensor_type_id = st.sensor_type_id
            WHERE ts.turbine_id = ?
            ORDER BY st.parameter_name
            """
            
            df_sensors = pd.read_sql(query, conn, params=[turbine_id])
            
            sensors_dict = {}
            for _, sensor_row in df_sensors.iterrows():
                param_name = sensor_row['parameter_name']
                sensors_dict[param_name] = {
                    "sensor_name": sensor_row['sensor_name'],
                    "unit_of_measurement": sensor_row['unit_of_measurement'],
                    "description": sensor_row['description'],
                    "sensor_type_id": int(sensor_row['sensor_type_id']),
                    "turbine_sensor_id": int(sensor_row['turbine_sensor_id'])
                }
            
            print(f" –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(sensors_dict)} —Å–µ–Ω—Å–æ—Ä–Ω–∏—Ö –º–µ—Ç–∞–¥–∞–Ω–∏—Ö –¥–ª—è {turbine_id}")
            return sensors_dict
            
        except Exception as e:
            print(f" –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å–µ–Ω—Å–æ—Ä—ñ–≤ –¥–ª—è {turbine_id}: {e}")
            return {}
        finally:
            conn.close()
    
    def save_to_new_delta_table(self, enriched_data: Dict[str, Any]):
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ Delta Lake —Ç–∞–±–ª–∏—Ü—é + JSON backup"""
    
        results = {
            'delta_success': False,
            'json_success': False
        }
    
        # === 1. DELTA LAKE –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø ===
        print(" –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ Delta Lake —Ç–∞–±–ª–∏—Ü—é...")
        try:
            # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö
            flat_data = self._prepare_new_table_data(enriched_data)
        
            df = daft.from_pydict({
                key: [value] for key, value in flat_data.items()
            })
        
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ Delta Lake
            delta_path = f"az://{CONTAINER_NAME}/{NEW_DELTA_TABLE_PATH}"
            print(f" –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤: {delta_path}")
            print(f" –ó–∞–ø–∏—Å ID: {flat_data.get('record_id', 'unknown')}")
        
            df.write_deltalake(
                delta_path,
                io_config=self.io_config,
                mode="append"
            )
        
            print(f" Delta Lake: –£–°–ü–Ü–®–ù–û –∑–±–µ—Ä–µ–∂–µ–Ω–æ!")
            results['delta_success'] = True
        
        except Exception as e:
            print(f" Delta Lake –ø–æ–º–∏–ª–∫–∞: {e}")
            results['delta_success'] = False
    
    # === 2. JSON BACKUP –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø (–ó–ê–í–ñ–î–ò) ===
        print(" –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è JSON backup...")
        try:
            current_time = datetime.now(timezone.utc)
            turbine_id = enriched_data.get('turbine_id', 'unknown')
        
            timestamp_str = current_time.strftime('%H%M%S_%f')[:-3]
            blob_name = f"enriched-telemetry-backup/year={current_time.year}/month={current_time.month:02d}/day={current_time.day:02d}/turbine={turbine_id}/enriched_{timestamp_str}.json"
        
            blob_client = self.blob_service.get_blob_client(
                container=CONTAINER_NAME,
                blob=blob_name
            )
        
            json_data = json.dumps(enriched_data, ensure_ascii=False, indent=2)
            blob_client.upload_blob(json_data, overwrite=True)
        
            print(f" JSON backup: {blob_name}")
            results['json_success'] = True
        
        except Exception as e:
            print(f" JSON backup –ø–æ–º–∏–ª–∫–∞: {e}")
            results['json_success'] = False
    
        if results['delta_success'] and results['json_success']:
            print(" –î–≤–∞ —Ñ–æ—Ä–º–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
        elif results['delta_success']:
            print(" Delta Lake OK, –∞–ª–µ JSON backup –ø—Ä–æ–≤–∞–ª–∏–≤—Å—è")
        elif results['json_success']:
            print(" JSON backup OK, –∞–ª–µ Delta Lake –ø—Ä–æ–≤–∞–ª–∏–≤—Å—è")
        else:
            print("–î–≤–∞ —Ñ–æ—Ä–º–∞—Ç–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—è!")
    
        return results['delta_success']
    
    def _prepare_new_table_data(self, enriched_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –ü–û–í–ù–ò–• –¥–∞–Ω–∏—Ö –¥–ª—è –Ω–æ–≤–æ—ó —Ç–∞–±–ª–∏—Ü—ñ"""
        current_time = datetime.now(timezone.utc)
        turbine_id = enriched_data.get('turbine_id', 'unknown')
        
        flat_data = {
            # –ë–∞–∑–æ–≤—ñ –¥–∞–Ω—ñ
            'record_id': f"{turbine_id}_{current_time.strftime('%Y%m%d_%H%M%S_%f')[:-3]}",
            'turbine_id': turbine_id,
            'timestamp': enriched_data.get('timestamp', ''),
            'processing_timestamp': current_time.isoformat(),
            
            # –¢–µ–ª–µ–º–µ—Ç—Ä–∏—á–Ω—ñ –¥–∞–Ω—ñ
            'output_power': float(enriched_data.get('output_power', 0)),
            'rotor_rpm': float(enriched_data.get('rotor_rpm', 0)),
            'max_power_limit': float(enriched_data.get('max_power_limit', 0)),
            'voltage': float(enriched_data.get('voltage', 0)),
            'current': float(enriched_data.get('current', 0)),
            'power_factor': float(enriched_data.get('power_factor', 0)),
            
            # –ü–∞—Ä—Ç–∏—Ü—ñ–æ–Ω—É–≤–∞–Ω–Ω—è
            'partition_year': current_time.year,
            'partition_month': current_time.month,
            'partition_day': current_time.day,
            'partition_turbine': turbine_id,
        }
        
        # –ú–µ—Ç–∞–¥–∞–Ω—ñ —Ç—É—Ä–±—ñ–Ω–∏
        turbine_meta = enriched_data.get('turbine_metadata', {})
        flat_data.update({
            'turbine_name': str(turbine_meta.get('turbine_name', '')),
            'location_lat': float(turbine_meta.get('location_lat', 0)) if turbine_meta.get('location_lat') else 0.0,
            'location_lng': float(turbine_meta.get('location_lng', 0)) if turbine_meta.get('location_lng') else 0.0,
            'manufacturer': str(turbine_meta.get('manufacturer', '')),
            'model': str(turbine_meta.get('model', '')),
            'nominal_power_kw': int(turbine_meta.get('nominal_power_kw', 0)) if turbine_meta.get('nominal_power_kw') else 0,
            'installation_date': str(turbine_meta.get('installation_date', '')),
            'turbine_status': str(turbine_meta.get('status', '')),
        })
        
        # –†–æ–∑—Ä–∞—Ö—É–Ω–∫–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏
        calc_metrics = enriched_data.get('calculated_metrics', {})
        flat_data.update({
            'efficiency_percent': float(calc_metrics.get('efficiency_percent', 0)),
            'operational_status': str(calc_metrics.get('operational_status', '')),
            'calculated_power_kw': float(calc_metrics.get('calculated_power_kw', 0)),
        })
        
        #  –ü–û–í–ù–Ü –µ–∫–æ–ª–æ–≥—ñ—á–Ω—ñ –¥–∞–Ω—ñ
        env_data = enriched_data.get('environmental_data', {})
        flat_data.update({
            'wind_speed_ms': float(env_data.get('wind_speed_ms', 0)),
            'wind_direction_degrees': int(env_data.get('wind_direction_degrees', 0)),
            'temperature_celsius': float(env_data.get('temperature_celsius', 0)),
            'humidity_percent': float(env_data.get('humidity_percent', 0)),
            'air_pressure_hpa': float(env_data.get('air_pressure_hpa', 0)),
            'visibility_km': float(env_data.get('visibility_km', 0)),
            'precipitation_mm': float(env_data.get('precipitation_mm', 0)),
        })
        
        #  –ü–û–í–ù–Ü –¥–∞–Ω—ñ –æ–±—Å–ª—É–≥–æ–≤—É–≤–∞–Ω–Ω—è
        maintenance_data = enriched_data.get('maintenance_data', {})
        flat_data.update({
            'maintenance_status': str(maintenance_data.get('maintenance_status', '')),
            'last_maintenance_date': str(maintenance_data.get('last_maintenance_date', '')),
            'next_maintenance_date': str(maintenance_data.get('next_maintenance_date', '')),
            'efficiency_rating': float(maintenance_data.get('efficiency_rating', 0)),
            'operating_hours': float(maintenance_data.get('operating_hours', 0)),
            'maintenance_notes': str(maintenance_data.get('maintenance_notes', '')),
            'technician_name': str(maintenance_data.get('technician_name', '')),
        })
        
        #  –ü–û–í–ù–Ü –º–µ—Ç–∞–¥–∞–Ω—ñ –∑–±–∞–≥–∞—á–µ–Ω–Ω—è
        enrichment_info = enriched_data.get('enrichment_info', {})
        flat_data.update({
            'data_quality_score': float(enrichment_info.get('data_quality_score', 1.0)),
            'enrichment_version': str(enrichment_info.get('enrichment_version', '')),
            'source': str(enrichment_info.get('source', '')),
            'processed_by': str(enrichment_info.get('processed_by', '')),
        })
        
        # –î–û–î–ê–¢–ö–û–í–Ü –º–µ—Ç–∞–¥–∞–Ω—ñ
        sensor_metadata = enriched_data.get('sensor_metadata', {})
        flat_data.update({
            'sensor_count': len(sensor_metadata),
            'has_environmental_data': len(env_data) > 0,
            'has_maintenance_data': len(maintenance_data) > 0,
            'record_version': '8.0',
        })
        
        return flat_data
    
    def _save_json_backup(self, enriched_data: Dict[str, Any]):
        try:
            current_time = datetime.now(timezone.utc)
            turbine_id = enriched_data.get('turbine_id', 'unknown')
            
            timestamp_str = current_time.strftime('%H%M%S_%f')[:-3]
            blob_name = f"enriched-telemetry-backup/year={current_time.year}/month={current_time.month:02d}/day={current_time.day:02d}/turbine={turbine_id}/enriched_{timestamp_str}.json"
            
            blob_client = self.blob_service.get_blob_client(
                container=CONTAINER_NAME,
                blob=blob_name
            )
            
            json_data = json.dumps(enriched_data, ensure_ascii=False, indent=2)
            blob_client.upload_blob(json_data, overwrite=True)
            
            print(f" JSON backup: {blob_name}")
            
        except Exception as e:
            print(f" JSON backup –ø–æ–º–∏–ª–∫–∞: {e}")
    
    def process_all_turbines_new_table(self, records_per_turbine: int = 1):
        """–û–±—Ä–æ–±–∫–∞ –≤—Å—ñ—Ö —Ç—É—Ä–±—ñ–Ω –∑ –ù–û–í–û–Æ Delta Lake —Ç–∞–±–ª–∏—Ü–µ—é"""
        print(f"\n –ó–ê–ü–£–°–ö –û–ë–†–û–ë–ö–ò –ó DELTA LAKE –¢–ê–ë–õ–ò–¶–ï–Æ")
        print(f" –ó–∞–ø–∏—Å—ñ–≤ –Ω–∞ —Ç—É—Ä–±—ñ–Ω—É: {records_per_turbine}")

        
        turbine_ids = self.get_all_turbine_ids()
        
        if not turbine_ids:
            print(" –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Ç—É—Ä–±—ñ–Ω –¥–ª—è –æ–±—Ä–æ–±–∫–∏")
            return
        
        total_processed = 0
        successful_turbines = []
        failed_turbines = []
        delta_successful = 0
        delta_failed = 0
        
        for i, turbine_id in enumerate(turbine_ids, 1):
            print(f"\n--- –¢–£–†–ë–Ü–ù–ê {i}/{len(turbine_ids)}: {turbine_id} ---")
            
            try:
                enriched_data_list = self.get_enriched_data_for_turbine(turbine_id, records_per_turbine)
                
                if not enriched_data_list:
                    print(f" –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è {turbine_id}")
                    failed_turbines.append(f"{turbine_id} (–Ω–µ–º–∞—î –¥–∞–Ω–∏—Ö)")
                    continue
                
                example = enriched_data_list[0]
                print(f" –ü—Ä–∏–∫–ª–∞–¥ –¥–ª—è {turbine_id}:")
                print(f"   ‚Ä¢ –ü–æ—Ç—É–∂–Ω—ñ—Å—Ç—å: {example['output_power']} –∫–í—Ç")
                print(f"   ‚Ä¢ –ï—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å: {example['calculated_metrics']['efficiency_percent']}%")
                print(f"   ‚Ä¢ –í–∏—Ä–æ–±–Ω–∏–∫: {example['turbine_metadata']['manufacturer']}")
                print(f"   ‚Ä¢ –°—Ç–∞—Ç—É—Å –¢–û: {example['maintenance_data']['maintenance_status']}")
                print(f"   ‚Ä¢ –¢–µ—Ö–Ω—ñ–∫: {example['maintenance_data']['technician_name']}")
                print(f"   ‚Ä¢ –°–µ–Ω—Å–æ—Ä—ñ–≤: {len(example['sensor_metadata'])} —Ç–∏–ø—ñ–≤")
                print(f"   ‚Ä¢ –®–≤–∏–¥–∫—ñ—Å—Ç—å –≤—ñ—Ç—Ä—É: {example['environmental_data']['wind_speed_ms']} –º/—Å")
                print(f"   ‚Ä¢ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {example['environmental_data']['temperature_celsius']}¬∞C")
                
                turbine_delta_success = 0
                for j, enriched_data in enumerate(enriched_data_list, 1):
                    print(f"    –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–∞–ø–∏—Å—É {j}/{len(enriched_data_list)}")
                    
                    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –ù–û–í–£ —Ç–∞–±–ª–∏—Ü—é
                    delta_success = self.save_to_new_delta_table(enriched_data)
                    if delta_success:
                        delta_successful += 1
                        turbine_delta_success += 1
                    else:
                        delta_failed += 1
                    
                    total_processed += 1
                    time.sleep(0.3)
                
                successful_turbines.append(f"{turbine_id} ({len(enriched_data_list)} –∑–∞–ø–∏—Å—ñ–≤, {turbine_delta_success} Delta)")
                print(f" {turbine_id} –æ–±—Ä–æ–±–ª–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ")
                
            except Exception as e:
                print(f" –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ {turbine_id}: {e}")
                failed_turbines.append(f"{turbine_id} (–ø–æ–º–∏–ª–∫–∞: {str(e)[:50]})")
            
            if i < len(turbine_ids):
                time.sleep(0.5)
        
        # –ü—ñ–¥—Å—É–º–∫–æ–≤–∏–π –∑–≤—ñ—Ç
        print(f"\n" + "=" * 60)
        print(f" –ü–Ü–î–°–£–ú–ö–û–í–ò–ô –ó–í–Ü–¢ –ù–û–í–û–á –¢–ê–ë–õ–ò–¶–Ü")
        print(f" –í—Å—å–æ–≥–æ —Ç—É—Ä–±—ñ–Ω: {len(turbine_ids)}")
        print(f" –£—Å–ø—ñ—à–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ: {len(successful_turbines)}")
        print(f" –ü—Ä–æ–≤–∞–ª–∏–ª–æ—Å—è: {len(failed_turbines)}")
        print(f" –í—Å—å–æ–≥–æ –∑–∞–ø–∏—Å—ñ–≤ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {total_processed}")
        print(f" Delta Lake —É—Å–ø—ñ—à–Ω–æ: {delta_successful}")
        print(f" elta Lake –ø—Ä–æ–≤–∞–ª–∏–ª–æ—Å—è: {delta_failed}")
        print(f"üìÑ JSON backup: –≤—Å—ñ {total_processed} –∑–∞–ø–∏—Å–∏")
        
        if successful_turbines:
            print(f"\n –£—Å–ø—ñ—à–Ω—ñ —Ç—É—Ä–±—ñ–Ω–∏:")
            for turbine in successful_turbines:
                print(f"   ‚Ä¢ {turbine}")
        
        if failed_turbines:
            print(f"\n –ü—Ä–æ–±–ª–µ–º–Ω—ñ —Ç—É—Ä–±—ñ–Ω–∏:")
            for turbine in failed_turbines:
                print(f"   ‚Ä¢ {turbine}")

def main():
    
    processor = NewTableProcessor()
    processor.process_all_turbines_new_table(records_per_turbine=1)
    
    print("\n" + "=" * 80)
    print(" –î–ï–ú–û–ù–°–¢–†–ê–¶–Ü–Ø –ó –ù–û–í–û–Æ –¢–ê–ë–õ–ò–¶–ï–Æ –ó–ê–í–ï–†–®–ï–ù–ê!")
    print(" –°—Ç–≤–æ—Ä–µ–Ω–∞ –Ω–æ–≤–∞ Delta Lake —Ç–∞–±–ª–∏—Ü—è –∑ –ø–æ–≤–Ω–æ—é —Å—Ö–µ–º–æ—é:")
    print("   ‚Ä¢ –í—Å—ñ —Ç–µ–ª–µ–º–µ—Ç—Ä–∏—á–Ω—ñ –¥–∞–Ω—ñ")
    print("   ‚Ä¢ –ü–æ–≤–Ω—ñ –º–µ—Ç–∞–¥–∞–Ω—ñ —Ç—É—Ä–±—ñ–Ω")
    print("   ‚Ä¢ –°–µ–Ω—Å–æ—Ä–Ω—ñ –º–µ—Ç–∞–¥–∞–Ω—ñ (6 —Ç–∏–ø—ñ–≤ –Ω–∞ —Ç—É—Ä–±—ñ–Ω—É)")
    print("   ‚Ä¢ –ï–∫–æ–ª–æ–≥—ñ—á–Ω—ñ –¥–∞–Ω—ñ (7 –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –ø–æ–≥–æ–¥–∏)")
    print("   ‚Ä¢ –î–∞–Ω—ñ –¢–û (—Å—Ç–∞—Ç—É—Å, –¥–∞—Ç–∏, —Ç–µ—Ö–Ω—ñ–∫–∏, –Ω–æ—Ç–∞—Ç–∫–∏)")
    print("   ‚Ä¢ –†–æ–∑—Ä–∞—Ö—É–Ω–∫–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏")
    print("   ‚Ä¢ –î–æ–¥–∞—Ç–∫–æ–≤—ñ –º–µ—Ç–∞–¥–∞–Ω—ñ")
    print(f"üÜï –ù–æ–≤–∞ —Ç–∞–±–ª–∏—Ü—è: {NEW_DELTA_TABLE_PATH}")
    print(" JSON backup –¥–ª—è –≤—Å—ñ—Ö –∑–∞–ø–∏—Å—ñ–≤")

if __name__ == "__main__":
    main()